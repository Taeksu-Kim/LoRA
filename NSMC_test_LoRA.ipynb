{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY9gIZoPREnL",
    "outputId": "edf5f323-7a66-4af7-96ed-bf8125d36890"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.7 torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaqC97q55ww-",
    "outputId": "6a50f6f2-b584-4d3e-a7bd-df9f289ddeab"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/microsoft/LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK-RF0Kb6i7u",
    "outputId": "cef4c1e9-2092-4a55-a457-dc215098e19f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Taeksu-Kim/LoRA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm_68A_76rbh",
    "outputId": "1b82640d-8417-48c5-e133-f72b7965454a"
   },
   "outputs": [],
   "source": [
    "cd LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OD4_Ea-u3JJ5",
    "outputId": "06de1c92-6401-4973-8a1e-7c7391542360"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1-9-CJgquS0z9ZihSboSla_uwJ3ouvpxP\n",
    "!gdown https://drive.google.com/uc?id=1-0kFcLCBtFvI4n8agpykJpzdUahkvbcF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "soWE65AlSDP9"
   },
   "outputs": [],
   "source": [
    "# common\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import ElectraForSequenceClassification\n",
    "\n",
    "# custom\n",
    "from convert_lora import LoRA_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kOxo_8pmc0tI"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OyV4zC-teD-Y"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"monologg/koelectra-base-v3-discriminator\"\n",
    "\n",
    "epochs = 300\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-2\n",
    "batch_size = 64\n",
    "\n",
    "early_stopping_patience = 5\n",
    "\n",
    "save_name = 'NSMC_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-g7KS5N_7xb_"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN7o2iM1oQ7e",
    "outputId": "228cd693-87f1-43d5-d135-a3173599376b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "document           0\n",
       "label              0\n",
       "fixed_document    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SzvA1YhHo62d"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mx2YPbyE5MHF"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOZN3kde4NXu",
    "outputId": "e03dc9c4-f43a-40ed-8488-a60db4a5b003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "document          0\n",
       "label             0\n",
       "fixed_document    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JgEF17wK5FCy"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "7590d2a1b2594e6287f1a9359967b9d9",
      "f0ad0481b29f49db9ea0368963e6aecd",
      "191c6ee8cdef4f35bdcb2a57a2dd88d7",
      "dfea21b0276c4ac58901b0d9e3110fbb",
      "e9c9544eb77c41988c144189704999fb",
      "bcc94c4459be4e76b0899a6a8626ae53",
      "4ee2cbb7b6cc4fa489bc469fa21f8a65",
      "48995d15e77f416a975298d6fba03b28",
      "bd701a318a074eec911f173ccc7df5cb",
      "65bfc66cc32f4cec84be2df19617ccee",
      "b1fdfede71b94d3d94c3d80fae14c530",
      "5f042cffb9194a86b1f459770f2183e0",
      "0d82f3b0ea1e43f6ad9d58e2d144c71d",
      "6ae1dff0ccd641298df5748f704c1c80",
      "78fcb5eab31d4231b807cb7ebb2ebf09",
      "5ad4ee453d7b47fea910c63abea9f917",
      "931da2712b8a4ffca89514f9a77c5bf6",
      "070a3310f87d4755add3301cb0adcc7e",
      "f24523b0c97745f8966edd2c43678f9d",
      "4544c7e504e341fe976f6795057cd5ed",
      "3b73a07d73ee4340b0611d2eebbefa90",
      "f2ecccc0a45f4d779394239b590f1464",
      "8f3a768fec9e4f7bbb004ad1bd2ccf4c",
      "ee4bf8faf1024b4f9fe7fc5c3d335372",
      "f4da6b46194449fd8ebd4a0657e40fbd",
      "32738c31531847a6b120fefe5a8c5188",
      "73cf6faa953f49d895b3914d0e6ab225",
      "dc5bb5bc523740b188a22c4d466ad3d7",
      "0a288bf3194240d994327f440401e9a4",
      "e1e71a9efc724e83b5dc3c5fa0f472f4",
      "82a7937b4c594512babbb24156dce3ff",
      "3dba7670543747e5a66ce7ca2d7645f6",
      "8ea96d5d13c6428f8490af6a0c248b35"
     ]
    },
    "id": "Vcy_7abBaWGX",
    "outputId": "0632f27d-2268-4b1b-aaa5-751d2dc88d19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c47828a62b44e5b619f7014eb17921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd37c5203e88488282fd190982983d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003759213983476eba35b8c8b4d19875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hBob5L-SZW7Q"
   },
   "outputs": [],
   "source": [
    "def cal_token_len(text, tokenizer):\n",
    "    return len(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsFzl3chZW93",
    "outputId": "2415fd12-cb24-44a5-9844-f4af13df2b3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149985/149985 [00:41<00:00, 3656.45it/s]\n"
     ]
    }
   ],
   "source": [
    "tar_df = train_df\n",
    "\n",
    "tar_df['token_len'] = [ cal_token_len(str(tar_df.iloc[i]['fixed_document']), tokenizer) for i in tqdm(range(tar_df.shape[0])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mx6dRe2uaFj-",
    "outputId": "414a4430-deab-4d11-cc7b-977a1140f9f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49994/49994 [00:13<00:00, 3702.67it/s]\n"
     ]
    }
   ],
   "source": [
    "tar_df = test_df\n",
    "\n",
    "tar_df['token_len'] = [ cal_token_len(str(tar_df.iloc[i]['fixed_document']), tokenizer) for i in tqdm(range(tar_df.shape[0])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaGKGsU4ZXAo",
    "outputId": "d988500c-739e-46bc-b89b-0ecd2f699f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% length : 62.0\n",
      "98% length : 76.0\n",
      "99% length : 80.0\n",
      "100% length : 142.0\n"
     ]
    }
   ],
   "source": [
    "tar_df = train_df\n",
    "\n",
    "tar_per_list = [95,98,99,100]\n",
    "tar_col = tar_df['token_len']\n",
    "\n",
    "for i in tar_per_list:\n",
    "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AngXCh8kLJAY",
    "outputId": "ba26e6ca-2a40-4f9b-81ca-1782d66afc86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% length : 62.0\n",
      "98% length : 76.0\n",
      "99% length : 80.0\n",
      "100% length : 112.0\n"
     ]
    }
   ],
   "source": [
    "tar_df = test_df\n",
    "\n",
    "tar_per_list = [95,98,99,100]\n",
    "tar_col = tar_df['token_len']\n",
    "\n",
    "for i in tar_per_list:\n",
    "    print('{}% length : {}'.format(i, np.percentile(tar_col,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uAh_OP14ZXF5"
   },
   "outputs": [],
   "source": [
    "max_input_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx-bHVUy9Mly",
    "outputId": "ceaafdad-a1b0-468d-bbc7-23e2ecb63539"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'document', 'label', 'fixed_document', 'token_len'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "C-oykEIycXwS"
   },
   "outputs": [],
   "source": [
    "train, valid =  train_test_split(train_df, test_size=0.2, stratify=train_df['label'],random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EHnr6x_4bk0W"
   },
   "outputs": [],
   "source": [
    "class movie_review_dataset(Dataset):\n",
    "\n",
    "  def __init__(self, df, max_input_len):\n",
    "    self.df = df\n",
    "    self.max_input_len = max_input_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.df.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    batch = tokenizer(self.df['fixed_document'].iloc[index],\n",
    "                      max_length=self.max_input_len, \n",
    "                      padding='max_length', \n",
    "                      truncation='only_first',\n",
    "                      return_tensors='pt',\n",
    "                      )\n",
    "    batch = {key: value[0] for key, value in batch.items()}\n",
    "\n",
    "    batch['labels'] = torch.tensor(self.df['label'].iloc[index], dtype=int)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Uee1UbQRbthI"
   },
   "outputs": [],
   "source": [
    "train_dataset = movie_review_dataset(train, max_input_len)\n",
    "valid_dataset = movie_review_dataset(valid, max_input_len)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "woHDPphObk21"
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "f69c062002254e1ba62b0161fe775862",
      "9d550164ea6446d4876c60f5059a0fae",
      "ed220b2939a446b7b7aad2dd1420ddd7",
      "e9f42b2016114e098f3c711a12d29543",
      "f7aeebbf48c34c99b05b9d10fde5c504",
      "b84cd498a24a4adeac50432edd7c27e7",
      "10672292bd2c41f09058fbeb02e0b46c",
      "5207fbcbfc1c4230a725d26f4dd4c4e5",
      "bab36070e24a4e149776f0713a786f23",
      "1e023bd99c684dd5a70dc24c1ef69ffb",
      "994bcdb9695b41a3bf607cfe62c773dd"
     ]
    },
    "id": "Ovxe7416VCg2",
    "outputId": "6347ca4f-ea68-4dd0-f2e6-2c83e92d002e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0c023dd5aa494395fdd359a0ba85a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = ElectraForSequenceClassification.from_pretrained(model_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBX0RCz_VDTe",
    "outputId": "4edfea4c-41f8-435c-f335-3d27d275ca4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ElectraForSequenceClassification                             --\n",
       "├─ElectraModel: 1-1                                          --\n",
       "│    └─ElectraEmbeddings: 2-1                                --\n",
       "│    │    └─Embedding: 3-1                                   26,880,000\n",
       "│    │    └─Embedding: 3-2                                   393,216\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─ElectraEncoder: 2-2                                   --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "├─ElectraClassificationHead: 1-2                             --\n",
       "│    └─Linear: 2-3                                           590,592\n",
       "│    └─Dropout: 2-4                                          --\n",
       "│    └─Linear: 2-5                                           1,538\n",
       "=====================================================================================\n",
       "Total params: 112,922,882\n",
       "Trainable params: 112,922,882\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VW-3rYZ_XFVN",
    "outputId": "f469f2ef-c180-4059-87ff-dfc18e18b00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkUUJ9VRAjwU",
    "outputId": "d536a300-30e3-4c0d-c2f5-398d444d5398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n"
     ]
    }
   ],
   "source": [
    "tar_linear_layers = {'electra': ['query', 'key', 'value']}\n",
    "# tar_embedding_layers = {'electra': ['shared', 'embed_tokens', 'relative_attention_bias']}\n",
    "tar_embedding_layers = {}\n",
    "keep_layers = {}\n",
    "\n",
    "model = LoRA_converter(base_model=base_model, \n",
    "                       tar_linear_layers=tar_linear_layers,\n",
    "                       tar_embedding_layers=tar_embedding_layers,\n",
    "                       keep_layers=keep_layers,\n",
    "                       lora_r=16, \n",
    "                       lora_alpha=1,\n",
    "                       lora_dropout=0.1).base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCoolMrLNbpi",
    "outputId": "6252b497-67fc-4b53-bb65-dc9704f0a30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ElectraForSequenceClassification                             --\n",
       "├─ElectraModel: 1-1                                          --\n",
       "│    └─ElectraEmbeddings: 2-1                                --\n",
       "│    │    └─Embedding: 3-1                                   (26,880,000)\n",
       "│    │    └─Embedding: 3-2                                   (393,216)\n",
       "│    │    └─Embedding: 3-3                                   (1,536)\n",
       "│    │    └─LayerNorm: 3-4                                   (1,536)\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─ElectraEncoder: 2-2                                   --\n",
       "│    │    └─ModuleList: 3-6                                  85,939,200\n",
       "├─ElectraClassificationHead: 1-2                             --\n",
       "│    └─Linear: 2-3                                           (590,592)\n",
       "│    └─Dropout: 2-4                                          --\n",
       "│    └─Linear: 2-5                                           (1,538)\n",
       "=====================================================================================\n",
       "Total params: 113,807,618\n",
       "Trainable params: 884,736\n",
       "Non-trainable params: 112,922,882\n",
       "====================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ds4qdluIP2JD",
    "outputId": "dc9d977b-88d9-44a6-a9dc-2e9dab618bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.0.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.1.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.2.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.3.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.4.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.5.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.6.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.7.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.8.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.9.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.10.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.query with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.key with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n",
      "Replace electra.encoder.layer.11.attention.self.value with lora linear\n"
     ]
    }
   ],
   "source": [
    "tar_linear_layers = {'electra': ['query', 'key', 'value']}\n",
    "# tar_embedding_layers = {'electra': ['shared', 'embed_tokens', 'relative_attention_bias']}\n",
    "tar_embedding_layers = {}\n",
    "keep_layers = {'classifier':['dense']}\n",
    "\n",
    "model = LoRA_converter(base_model=base_model, \n",
    "                       tar_linear_layers=tar_linear_layers,\n",
    "                       tar_embedding_layers=tar_embedding_layers,\n",
    "                       keep_layers=keep_layers,\n",
    "                       lora_r=16, \n",
    "                       lora_alpha=1,\n",
    "                       lora_dropout=0.1).base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEu85C0KP3rE",
    "outputId": "28c1d39c-0544-42e2-d3ff-360c709541d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ElectraForSequenceClassification                             --\n",
       "├─ElectraModel: 1-1                                          --\n",
       "│    └─ElectraEmbeddings: 2-1                                --\n",
       "│    │    └─Embedding: 3-1                                   (26,880,000)\n",
       "│    │    └─Embedding: 3-2                                   (393,216)\n",
       "│    │    └─Embedding: 3-3                                   (1,536)\n",
       "│    │    └─LayerNorm: 3-4                                   (1,536)\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─ElectraEncoder: 2-2                                   --\n",
       "│    │    └─ModuleList: 3-6                                  85,939,200\n",
       "├─ElectraClassificationHead: 1-2                             --\n",
       "│    └─Linear: 2-3                                           590,592\n",
       "│    └─Dropout: 2-4                                          --\n",
       "│    └─Linear: 2-5                                           (1,538)\n",
       "=====================================================================================\n",
       "Total params: 113,807,618\n",
       "Trainable params: 1,475,328\n",
       "Non-trainable params: 112,332,290\n",
       "====================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RoT2h-IfmG-",
    "outputId": "d96b37dc-32b1-4020-aa7d-df14b39f7e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "XT3sizK_lDR0"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "O_QU0EYnOoz9"
   },
   "outputs": [],
   "source": [
    "def cal_acc(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred = torch.argmax(y_pred, dim=-1).int()\n",
    "    matches = torch.eq(y_true, y_pred).int()\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = torch.sum(matches) / matches.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LvJAlFrmlDU3"
   },
   "outputs": [],
   "source": [
    "def train_step(batch, epoch, training):\n",
    "\n",
    "    batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs['logits']\n",
    "            loss = outputs['loss']\n",
    "\n",
    "            acc = cal_acc(logits, batch['labels'])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        return loss, acc, round(lr, 10)\n",
    "\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs['logits']\n",
    "            loss = outputs['loss']\n",
    "\n",
    "            acc = cal_acc(logits, batch['labels'])\n",
    "\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LBhQX6ttD1H5"
   },
   "outputs": [],
   "source": [
    "# class color:\n",
    "PURPLE = '\\033[95m'\n",
    "CYAN = '\\033[96m'\n",
    "DARKCYAN = '\\033[36m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERLINE = '\\033[4m'\n",
    "END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kv-2vjF24nTY",
    "outputId": "4faf2ada-4af0-4b73-f816-37b04238ed89"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# train\n",
    "\n",
    "loss_plot, val_loss_plot = [], []\n",
    "lrs = []\n",
    "\n",
    "check_list = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = 100\n",
    "\n",
    "best_epoch = 0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gc.collect()\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader), total=train_dataloader.__len__())\n",
    "    training = True\n",
    "    for batch_idx, batch in tqdm_dataset:\n",
    "        batch_loss, batch_acc, lr = train_step(batch, epoch, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            '%+10s' % 'Epoch': epoch + 1,\n",
    "            '%10s' % GREEN + 'Loss' : '{:.4f}'.format(total_loss/(batch_idx+1)) + END,\n",
    "            '%10s' % YELLOW + 'acc' : '{:.4f}'.format(total_acc/(batch_idx+1)) + END,\n",
    "            '%5s' % 'LR' : lr,\n",
    "        })\n",
    "            \n",
    "    loss_plot.append(total_loss/(batch_idx+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(valid_dataloader), total=valid_dataloader.__len__())\n",
    "    training = False\n",
    "    for batch_idx, batch in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch, epoch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "\n",
    "        tqdm_dataset.set_postfix({\n",
    "            '%+12s' % 'Epoch': epoch + 1,\n",
    "            '%6s' % GREEN + 'Val Loss' : '{:.4f}'.format(total_val_loss/(batch_idx+1)) + END,\n",
    "            '%6s' % YELLOW + 'Val acc' : '{:.4f}'.format(total_val_acc/(batch_idx+1)) + END,\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch_idx+1)) \n",
    "\n",
    "    cur_val_loss = round(float((total_val_loss/(batch_idx+1)).detach().cpu()), 3)\n",
    "    cur_val_acc = round(float((total_val_acc/(batch_idx+1))), 3)\n",
    "\n",
    "    if cur_val_acc > best_val_acc:\n",
    "        print(YELLOW + 'Best_Val_acc is updated from {:>5} to {:>5} on epoch {}'.format(best_val_acc, cur_val_acc, epoch+1) + END)\n",
    "        best_val_acc = cur_val_acc\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), './'+save_name+'.ckpt')\n",
    "\n",
    "    else:\n",
    "        patience += 1\n",
    "    \n",
    "    lrs.append(lr)\n",
    "    \n",
    "    if patience == early_stopping_patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77PFV65oayL_"
   },
   "outputs": [],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "9ZwKB-qmLNZj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./'+save_name+'.ckpt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "lCOajkIDgCJs"
   },
   "outputs": [],
   "source": [
    "def inference(text, max_input_len):\n",
    "    labels = ['부정', '긍정']\n",
    "\n",
    "    inputs = torch.tensor(tokenizer.encode(str(text),\n",
    "                                           max_length=max_input_len, \n",
    "                                           padding='max_length', \n",
    "                                           truncation='only_first'), \n",
    "                              dtype=int).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(inputs)[0].detach().to('cpu')\n",
    "    \n",
    "    outputs = int(torch.argmax(logits, dim=-1)[0])\n",
    "    score = float(torch.max(nn.Softmax(dim=-1)(logits)))\n",
    "\n",
    "    \n",
    "    return labels[outputs], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "DmJUg1slNpFO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('부정', 0.9271074533462524)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '뭐 이따구로 영화를 만들어놨어 ㅋㅋ'\n",
    "inference(text, max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "7HBQgotp6NNK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('부정', 0.6981436610221863)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '명작이라는 평을 이해할 수가 없다. 이딴 게?'\n",
    "inference(text, max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "d6aHMWz56nHZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('긍정', 0.962390124797821)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '두 번 봐도 질리지 않는 영화'\n",
    "inference(text, max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "U0CAVsVL7Ltj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('부정', 0.862804114818573)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '어이가 없네 ㅋㅋㅋㅋ'\n",
    "inference(text, max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dJQtWyX6JCe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "070a3310f87d4755add3301cb0adcc7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a288bf3194240d994327f440401e9a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d82f3b0ea1e43f6ad9d58e2d144c71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_931da2712b8a4ffca89514f9a77c5bf6",
      "placeholder": "​",
      "style": "IPY_MODEL_070a3310f87d4755add3301cb0adcc7e",
      "value": "Downloading: 100%"
     }
    },
    "10672292bd2c41f09058fbeb02e0b46c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "191c6ee8cdef4f35bdcb2a57a2dd88d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48995d15e77f416a975298d6fba03b28",
      "max": 467,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd701a318a074eec911f173ccc7df5cb",
      "value": 467
     }
    },
    "1e023bd99c684dd5a70dc24c1ef69ffb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32738c31531847a6b120fefe5a8c5188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dba7670543747e5a66ce7ca2d7645f6",
      "placeholder": "​",
      "style": "IPY_MODEL_8ea96d5d13c6428f8490af6a0c248b35",
      "value": " 61.0/61.0 [00:00&lt;00:00, 1.36kB/s]"
     }
    },
    "3b73a07d73ee4340b0611d2eebbefa90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dba7670543747e5a66ce7ca2d7645f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4544c7e504e341fe976f6795057cd5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48995d15e77f416a975298d6fba03b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee2cbb7b6cc4fa489bc469fa21f8a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5207fbcbfc1c4230a725d26f4dd4c4e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad4ee453d7b47fea910c63abea9f917": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f042cffb9194a86b1f459770f2183e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d82f3b0ea1e43f6ad9d58e2d144c71d",
       "IPY_MODEL_6ae1dff0ccd641298df5748f704c1c80",
       "IPY_MODEL_78fcb5eab31d4231b807cb7ebb2ebf09"
      ],
      "layout": "IPY_MODEL_5ad4ee453d7b47fea910c63abea9f917"
     }
    },
    "65bfc66cc32f4cec84be2df19617ccee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ae1dff0ccd641298df5748f704c1c80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f24523b0c97745f8966edd2c43678f9d",
      "max": 263326,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4544c7e504e341fe976f6795057cd5ed",
      "value": 263326
     }
    },
    "73cf6faa953f49d895b3914d0e6ab225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7590d2a1b2594e6287f1a9359967b9d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0ad0481b29f49db9ea0368963e6aecd",
       "IPY_MODEL_191c6ee8cdef4f35bdcb2a57a2dd88d7",
       "IPY_MODEL_dfea21b0276c4ac58901b0d9e3110fbb"
      ],
      "layout": "IPY_MODEL_e9c9544eb77c41988c144189704999fb"
     }
    },
    "78fcb5eab31d4231b807cb7ebb2ebf09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b73a07d73ee4340b0611d2eebbefa90",
      "placeholder": "​",
      "style": "IPY_MODEL_f2ecccc0a45f4d779394239b590f1464",
      "value": " 263k/263k [00:00&lt;00:00, 264kB/s]"
     }
    },
    "82a7937b4c594512babbb24156dce3ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ea96d5d13c6428f8490af6a0c248b35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f3a768fec9e4f7bbb004ad1bd2ccf4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee4bf8faf1024b4f9fe7fc5c3d335372",
       "IPY_MODEL_f4da6b46194449fd8ebd4a0657e40fbd",
       "IPY_MODEL_32738c31531847a6b120fefe5a8c5188"
      ],
      "layout": "IPY_MODEL_73cf6faa953f49d895b3914d0e6ab225"
     }
    },
    "931da2712b8a4ffca89514f9a77c5bf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "994bcdb9695b41a3bf607cfe62c773dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d550164ea6446d4876c60f5059a0fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b84cd498a24a4adeac50432edd7c27e7",
      "placeholder": "​",
      "style": "IPY_MODEL_10672292bd2c41f09058fbeb02e0b46c",
      "value": "Downloading: 100%"
     }
    },
    "b1fdfede71b94d3d94c3d80fae14c530": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b84cd498a24a4adeac50432edd7c27e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bab36070e24a4e149776f0713a786f23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bcc94c4459be4e76b0899a6a8626ae53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd701a318a074eec911f173ccc7df5cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dc5bb5bc523740b188a22c4d466ad3d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfea21b0276c4ac58901b0d9e3110fbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65bfc66cc32f4cec84be2df19617ccee",
      "placeholder": "​",
      "style": "IPY_MODEL_b1fdfede71b94d3d94c3d80fae14c530",
      "value": " 467/467 [00:00&lt;00:00, 16.2kB/s]"
     }
    },
    "e1e71a9efc724e83b5dc3c5fa0f472f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9c9544eb77c41988c144189704999fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9f42b2016114e098f3c711a12d29543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e023bd99c684dd5a70dc24c1ef69ffb",
      "placeholder": "​",
      "style": "IPY_MODEL_994bcdb9695b41a3bf607cfe62c773dd",
      "value": " 452M/452M [00:06&lt;00:00, 65.8MB/s]"
     }
    },
    "ed220b2939a446b7b7aad2dd1420ddd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5207fbcbfc1c4230a725d26f4dd4c4e5",
      "max": 451741507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bab36070e24a4e149776f0713a786f23",
      "value": 451741507
     }
    },
    "ee4bf8faf1024b4f9fe7fc5c3d335372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc5bb5bc523740b188a22c4d466ad3d7",
      "placeholder": "​",
      "style": "IPY_MODEL_0a288bf3194240d994327f440401e9a4",
      "value": "Downloading: 100%"
     }
    },
    "f0ad0481b29f49db9ea0368963e6aecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcc94c4459be4e76b0899a6a8626ae53",
      "placeholder": "​",
      "style": "IPY_MODEL_4ee2cbb7b6cc4fa489bc469fa21f8a65",
      "value": "Downloading: 100%"
     }
    },
    "f24523b0c97745f8966edd2c43678f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ecccc0a45f4d779394239b590f1464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4da6b46194449fd8ebd4a0657e40fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1e71a9efc724e83b5dc3c5fa0f472f4",
      "max": 61,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82a7937b4c594512babbb24156dce3ff",
      "value": 61
     }
    },
    "f69c062002254e1ba62b0161fe775862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d550164ea6446d4876c60f5059a0fae",
       "IPY_MODEL_ed220b2939a446b7b7aad2dd1420ddd7",
       "IPY_MODEL_e9f42b2016114e098f3c711a12d29543"
      ],
      "layout": "IPY_MODEL_f7aeebbf48c34c99b05b9d10fde5c504"
     }
    },
    "f7aeebbf48c34c99b05b9d10fde5c504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
